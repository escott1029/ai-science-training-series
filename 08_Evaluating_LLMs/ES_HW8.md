# Evaluating LLMs and Potential Pitfalls

Intro to AI-Driven Science on Supercomputers @ ALCF 2024

**Contact:** Marieme Ngom ([mngom@anl.gov](mailto:///mngom@anl.gov)), Bethany Lusch ([blusch@anl.gov](mailto:///blusch@anl.gov)), Sandeep Madireddy  ([smadireddy@anl.gov](mailto:///smadireddy@anl.gov)) 


[Overview of LLMs Evaluation](https://github.com/argonne-lcf/ai-science-training-series/blob/main/08_Evaluating_LLMs/LLM_Evaluation_Overview.pdf)

[Potential Pitfalls of LLMs](https://github.com/argonne-lcf/ai-science-training-series/blob/main/08_Evaluating_LLMs/LLM-Pitfalls.pdf)
    
[Link to breakout rooms forms](https://drive.google.com/drive/folders/1BN_aBlNU-7KVIcySntRtbkBXRGpkMSyz)

Other helpful links:
- [OpenAI tokenizer](https://platform.openai.com/tokenizer)
- [Chatbot Arena](https://chat.lmsys.org/)
- [Chatbot Guardrails Arena](https://huggingface.co/spaces/lighthouzai/guardrails-arena)

 
 **Homework**
 
What do you think is a particularly good use case for LLMs for science? How would you evaluate it?
Your answer does not need to be in paragraphs. When you submit your homework form, you can link to a file in your Github repo where you wrote your answer.


One interesting case for LLMs might be in science communication. I would be interested in seeing if a LLM can effectively take complex scientific concepts and explain them using less jargon in order to make science more tolerable for a wide audience. To evaluate my model, I would first test it with HELM. Then, to run my own test, I would construct a dataset of complex scientific paragraphs and simpler paragraphs describing the same thing. Then, I would train the model to match the complex paragraphs with the simple paragraphs about the same topic. Ultimately, I think that the use of LLMs can help to analyze complex large datasets faster and more efficiently than humans.
